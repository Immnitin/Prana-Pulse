# # -*- coding: utf-8 -*-
# """Untitled5.ipynb

# Automatically generated by Colab.

# Original file is located at
#     https://colab.research.google.com/drive/1YdKqPcTEbcATerrhUdXAXVDlrXdQ8W4W
# """

# import pandas as pd
# import numpy as np
# import pickle
# import shap
# import matplotlib.pyplot as plt

# from sklearn.model_selection import train_test_split
# from sklearn.linear_model import LogisticRegression
# from sklearn.preprocessing import StandardScaler
# from sklearn.metrics import accuracy_score, roc_auc_score, brier_score_loss

# import pandas as pd

# print("--- Advanced Diabetes Model Training Pipeline (New Dataset) ---")

# # --- 1. Data Loading ---
# try:
#     diabetes_data = pd.read_csv('diabetes_prediction_dataset.csv')
#     print("New diabetes dataset loaded successfully.")
# except FileNotFoundError:
#     print("Error: 'diabetes_prediction_dataset.csv' not found.")
#     exit()

# # --- 2. Data Preprocessing for Categorical Features ---
# # Convert categorical columns ('gender', 'smoking_history') into numerical format
# # We use one-hot encoding for this.
# print("Preprocessing categorical features...")
# # Handle the 'Other' gender value by removing it for simplicity in this model
# diabetes_data = diabetes_data[diabetes_data['gender'] != 'Other']
# diabetes_data = pd.get_dummies(diabetes_data, columns=['gender', 'smoking_history'], drop_first=True)

# # --- 3. Feature and Target Separation ---
# # The 'diabetes' column is the target
# X_features = diabetes_data.drop(columns='diabetes', axis=1)
# Y_target = diabetes_data['diabetes']
# print("Features and target separated.")

# from sklearn.model_selection import train_test_split

# # --- 4. Train-Test Split ---
# X_train_df, X_test_df, Y_train, Y_test = train_test_split(X_features, Y_target, test_size=0.2, stratify=Y_target, random_state=42)
# print("Data split into training and testing sets.")

# from sklearn.preprocessing import StandardScaler

# # --- 5. Data Standardization ---
# # We only scale the numerical columns, not the new one-hot encoded columns
# # Identify numerical columns to scale
# numerical_cols = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']
# scaler = StandardScaler()

# # Fit on the training data and transform both sets
# X_train_df[numerical_cols] = scaler.fit_transform(X_train_df[numerical_cols])
# X_test_df[numerical_cols] = scaler.transform(X_test_df[numerical_cols])
# print("Numerical data has been standardized.")

# from sklearn.linear_model import LogisticRegression

# # --- 6. Model Training ---
# model = LogisticRegression(solver='liblinear', max_iter=1000)
# model.fit(X_train_df, Y_train)
# print("Diabetes model training complete.")

# # --- 7. Advanced Model Evaluation ---
# print("\n--- Model Performance Metrics ---")
# y_pred = model.predict(X_test_df)
# y_pred_proba = model.predict_proba(X_test_df)[:, 1]

# from sklearn.metrics import accuracy_score, roc_auc_score, brier_score_loss

# accuracy = accuracy_score(Y_test, y_pred)
# print(f"Accuracy: {accuracy:.4f}")

# auroc = roc_auc_score(Y_test, y_pred_proba)
# print(f"AUROC Score: {auroc:.4f}")

# brier_score = brier_score_loss(Y_test, y_pred_proba)
# print(f"Brier Score Loss: {brier_score:.4f}")

# import shap

# # --- 8. Model Explainability (SHAP) ---
# print("\n--- Generating Model Explanations ---")
# # Use the model coefficients for LinearExplainer, as it's faster and exact for linear models
# explainer = shap.LinearExplainer(model, X_train_df)
# shap_values = explainer.shap_values(X_test_df)

# import matplotlib.pyplot as plt
# import shap
# import numpy as np

# plt.figure()
# # Ensure data is in a format compatible with shap.summary_plot
# # Convert DataFrames to NumPy arrays with float type if necessary
# shap_values_np = np.array(shap_values, dtype=float)
# X_test_np = X_test_df.values.astype(float)


# shap.summary_plot(shap_values_np, X_test_np, feature_names=X_test_df.columns.tolist(), show=False)
# plt.savefig('diabetes_shap_summary_plot_v2.png', bbox_inches='tight')
# plt.close()
# print("SHAP summary plot saved as 'diabetes_shap_summary_plot_v2.png'")

# # --- 9. Fairness Analysis (by Gender) ---
# print("\n--- Fairness Analysis (by Gender) ---")
# # Add predictions to the test DataFrame for analysis
# X_test_df['prediction'] = y_pred
# X_test_df['actual'] = Y_test

# # Separate by gender (gender_Male=1 for Male, gender_Male=0 for Female)
# male_group = X_test_df[X_test_df['gender_Male'] == 1]
# female_group = X_test_df[X_test_df['gender_Male'] == 0]

# if not male_group.empty and not female_group.empty:
#     male_accuracy = accuracy_score(male_group['actual'], male_group['prediction'])
#     female_accuracy = accuracy_score(female_group['actual'], female_group['prediction'])
#     print(f"Accuracy for Male group: {male_accuracy:.4f}")
#     print(f"Accuracy for Female group: {female_accuracy:.4f}")
#     if abs(male_accuracy - female_accuracy) > 0.05: # Using a 5% threshold
#         print("Warning: Potential bias detected. Accuracy difference is greater than 5%.")
#     else:
#         print("No significant accuracy difference detected between gender groups.")
# else:
#     print("Could not perform fairness analysis due to missing data in one of the gender groups.")

# import pickle

# # --- 10. Save the Final Model and Scaler ---
# print("\n--- Saving Final Artifacts ---")
# with open('diabetes_model.sav', 'wb') as model_file:
#     pickle.dump(model, model_file)
# print("Model saved successfully as 'diabetes_model.sav'")

# with open('diabetes_scaler.sav', 'wb') as scaler_file:
#     pickle.dump(scaler, scaler_file)
# print("Scaler saved successfully as 'diabetes_scaler.sav'")


import pandas as pd
import numpy as np
import pickle
import shap
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, roc_auc_score, brier_score_loss

print("--- Advanced Diabetes Model Training Pipeline (New Dataset) ---")

# --- 1. Data Loading (Using Relative Path) ---
try:
    # This will look for the CSV in the same folder the script is run from.
    diabetes_data = pd.read_csv('diabetes_prediction_dataset.csv')
    print("New diabetes dataset loaded successfully.")
except FileNotFoundError:
    print("Error: 'diabetes_prediction_dataset.csv' not found. Make sure it is in the '/backend' folder.")
    exit()

# --- 2. Data Preprocessing for Categorical Features ---
print("Preprocessing categorical features...")
# Handle the 'Other' gender value by removing it for simplicity in this model
diabetes_data = diabetes_data[diabetes_data['gender'] != 'Other']
# Convert categorical columns ('gender', 'smoking_history') into numerical format
diabetes_data = pd.get_dummies(diabetes_data, columns=['gender', 'smoking_history'], drop_first=True)

# --- 3. Feature and Target Separation ---
# The 'diabetes' column is the target for this dataset
X_features = diabetes_data.drop(columns='diabetes', axis=1)
Y_target = diabetes_data['diabetes']
print("Features and target separated.")

# --- 4. Train-Test Split ---
X_train_df, X_test_df, Y_train, Y_test = train_test_split(X_features, Y_target, test_size=0.2, stratify=Y_target, random_state=42)
print("Data split into training and testing sets.")

# --- 5. Data Standardization ---
# Identify only the numerical columns to scale
numerical_cols = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']
scaler = StandardScaler()

# Use .copy() to avoid a common warning in pandas
X_train_df_scaled = X_train_df.copy()
X_test_df_scaled = X_test_df.copy()

# Fit the scaler on the training data and transform both training and test sets
X_train_df_scaled[numerical_cols] = scaler.fit_transform(X_train_df[numerical_cols])
X_test_df_scaled[numerical_cols] = scaler.transform(X_test_df[numerical_cols])
print("Numerical data has been standardized.")

# --- 6. Model Training ---
model = LogisticRegression(solver='liblinear', max_iter=1000)
model.fit(X_train_df_scaled, Y_train)
print("Diabetes model training complete.")

# --- 7. Advanced Model Evaluation ---
print("\n--- Model Performance Metrics ---")
y_pred = model.predict(X_test_df_scaled)
y_pred_proba = model.predict_proba(X_test_df_scaled)[:, 1]

accuracy = accuracy_score(Y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")

auroc = roc_auc_score(Y_test, y_pred_proba)
print(f"AUROC Score: {auroc:.4f}")

brier_score = brier_score_loss(Y_test, y_pred_proba)
print(f"Brier Score Loss: {brier_score:.4f}")

# --- 8. Save the Final Model and Scaler ---
print("\n--- Saving Final Artifacts ---")
with open('diabetes_model.sav', 'wb') as model_file:
    pickle.dump(model, model_file)
print("Model saved successfully as 'diabetes_model.sav'")

with open('diabetes_scaler.sav', 'wb') as scaler_file:
    pickle.dump(scaler, scaler_file)
print("Scaler for diabetes model saved successfully as 'diabetes_scaler.sav'")
